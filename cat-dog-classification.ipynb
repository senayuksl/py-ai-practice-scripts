{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0a537d-0c21-41c7-8c06-893826c41390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b31658-b4ec-47ec-8112-acca38132758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32,(3,3),activation=\"relu\", input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3),activation=\"relu\", input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation=\"relu\", input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\", input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb53b3d-7e23-4814-a943-534ebba8b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling model\n",
    "from keras import optimizers\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizers.RMSprop(learning_rate=1e-4),metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a352d2b-4b14-43ef-9601-3ef6cbf9e974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6400 images belonging to 2 classes.\n",
      "Found 1600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#data generation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_directory=\"datasets/catdog/train\"\n",
    "validation_directory=\"datasets/catdog/validation\"\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(train_directory, target_size=(150,150), batch_size=20, class_mode=\"binary\")\n",
    "validation_generator=validation_datagen.flow_from_directory (validation_directory, target_size=(150,150), batch_size=20, class_mode=\"binary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62f892f-cb6a-49f4-b4f3-4ee77837a5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "320/320 [==============================] - 135s 412ms/step - loss: 0.6650 - acc: 0.5925 - val_loss: 0.6026 - val_acc: 0.6660\n",
      "Epoch 2/20\n",
      "320/320 [==============================] - 126s 395ms/step - loss: 0.5851 - acc: 0.6880 - val_loss: 0.5538 - val_acc: 0.7330\n",
      "Epoch 3/20\n",
      "320/320 [==============================] - 124s 389ms/step - loss: 0.5316 - acc: 0.7352 - val_loss: 0.5001 - val_acc: 0.7620\n",
      "Epoch 4/20\n",
      "320/320 [==============================] - 125s 389ms/step - loss: 0.4851 - acc: 0.7642 - val_loss: 0.4875 - val_acc: 0.7520\n",
      "Epoch 5/20\n",
      "320/320 [==============================] - 128s 400ms/step - loss: 0.4527 - acc: 0.7873 - val_loss: 0.4585 - val_acc: 0.7970\n",
      "Epoch 6/20\n",
      "320/320 [==============================] - 125s 391ms/step - loss: 0.4240 - acc: 0.8062 - val_loss: 0.4729 - val_acc: 0.7900\n",
      "Epoch 7/20\n",
      "320/320 [==============================] - 125s 390ms/step - loss: 0.3998 - acc: 0.8167 - val_loss: 0.4924 - val_acc: 0.7700\n",
      "Epoch 8/20\n",
      "320/320 [==============================] - 125s 390ms/step - loss: 0.3786 - acc: 0.8375 - val_loss: 0.4592 - val_acc: 0.7940\n",
      "Epoch 9/20\n",
      "320/320 [==============================] - 125s 391ms/step - loss: 0.3531 - acc: 0.8431 - val_loss: 0.4671 - val_acc: 0.7960\n",
      "Epoch 10/20\n",
      "320/320 [==============================] - 126s 393ms/step - loss: 0.3296 - acc: 0.8555 - val_loss: 0.4452 - val_acc: 0.8100\n",
      "Epoch 11/20\n",
      "320/320 [==============================] - 128s 399ms/step - loss: 0.3048 - acc: 0.8661 - val_loss: 0.5244 - val_acc: 0.7670\n",
      "Epoch 12/20\n",
      "320/320 [==============================] - 123s 383ms/step - loss: 0.2751 - acc: 0.8806 - val_loss: 0.4561 - val_acc: 0.8020\n",
      "Epoch 13/20\n",
      "320/320 [==============================] - 94s 293ms/step - loss: 0.2497 - acc: 0.8952 - val_loss: 0.4703 - val_acc: 0.7890\n",
      "Epoch 14/20\n",
      "320/320 [==============================] - 94s 294ms/step - loss: 0.2237 - acc: 0.9147 - val_loss: 0.4605 - val_acc: 0.7980\n",
      "Epoch 15/20\n",
      "320/320 [==============================] - 94s 293ms/step - loss: 0.1975 - acc: 0.9217 - val_loss: 0.5250 - val_acc: 0.7860\n",
      "Epoch 16/20\n",
      "320/320 [==============================] - 93s 291ms/step - loss: 0.1771 - acc: 0.9334 - val_loss: 0.5271 - val_acc: 0.7780\n",
      "Epoch 17/20\n",
      "320/320 [==============================] - 108s 337ms/step - loss: 0.1557 - acc: 0.9416 - val_loss: 0.5218 - val_acc: 0.8170\n",
      "Epoch 18/20\n",
      "320/320 [==============================] - 107s 333ms/step - loss: 0.1307 - acc: 0.9544 - val_loss: 0.5387 - val_acc: 0.7870\n",
      "Epoch 19/20\n",
      "320/320 [==============================] - 91s 283ms/step - loss: 0.1108 - acc: 0.9605 - val_loss: 0.5509 - val_acc: 0.8200\n",
      "Epoch 20/20\n",
      "320/320 [==============================] - 90s 282ms/step - loss: 0.0923 - acc: 0.9686 - val_loss: 0.6754 - val_acc: 0.7870\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "history =model.fit(train_generator, epochs=20, validation_data=validation_generator, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c05df87-5282-4f67-a797-a9b42b0d06d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m     10\u001b[0m epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m\n\u001b[1;32m---> 11\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,epochs), \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,epochs), history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,epochs), history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns #hata verdiği için ekledim \n",
    "\n",
    "#plt.style.use(seaborn-darkgrid)\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "epochs=20\n",
    "plt.plot(np.arange(0,epochs), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0,epochs), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0,epochs), history.history[\"acc\"], label=\"acc\")\n",
    "plt.plot(np.arange(0,epochs), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "\n",
    "plt.title(\"Training | Loss & Accuracy\")\n",
    "plt.xlabel(\"20-Epoch\")\n",
    "plt.ylabel(\"Loss&Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "#model.save(model/\"cat_dog_first.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17df6667-a7af-40b9-9865-e39f3ba722a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 74, 74, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 36, 36, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 17, 17, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating new model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import optimizers \n",
    "#normalde yukarıdaki üç satır yok hata verdiği için ekledim \n",
    "\n",
    "model_x = Sequential()\n",
    "\n",
    "model_x.add(layers.Conv2D(32,(3,3), activation=\"relu\", input_shape=(150,150,3)))\n",
    "model_x.add(layers.MaxPooling2D(2,2))\n",
    "model_x.add(layers.Conv2D(64,(3,3), activation=\"relu\", input_shape =(10,150,3)))\n",
    "model_x.add(layers.MaxPooling2D(2,2))\n",
    "model_x.add(layers.Conv2D(128,(3,3), activation=\"relu\", input_shape=(150,150,3)))\n",
    "model_x.add(layers.MaxPooling2D(2,2))\n",
    "model_x.add(layers.Conv2D(128,(3,3), activation=\"relu\", input_shape=(150,150,3)))\n",
    "model_x.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model_x.add(layers.Flatten())\n",
    "model_x.add(layers.Dropout(0.4))\n",
    "\n",
    "model_x.add(layers.Dense(512, activation=\"relu\"))\n",
    "model_x.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_x.summary()\n",
    "\n",
    "model_x.compile(loss=\"binary_crossentropy\", optimizer=optimizers.RMSprop(learning_rate=1e-4), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "873ec797-7ed4-4ee6-b76c-443018cd9906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6400 images belonging to 2 classes.\n",
      "Found 1600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#image data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator #normal kodda bu satır yok hata verdiği için ekledim \n",
    "train_datagen_x=ImageDataGenerator(rescale=1./255, rotation_range=45, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.3, zoom_range=0.3, \n",
    "                                   horizontal_flip=True, vertical_flip=True, fill_mode=\"nearest\")\n",
    "validation_datagen_x=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator_x=train_datagen_x.flow_from_directory(train_directory, target_size=(150,150), batch_size=16,class_mode=\"binary\")\n",
    "validation_generator_x=validation_datagen_x.flow_from_directory(validation_directory, target_size=(150,150), batch_size=16, class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a63eef8-d7cb-4fec-ba4d-cb528205865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sena\\AppData\\Local\\Temp\\ipykernel_27580\\253289770.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_x =model_x.fit_generator(train_generator_x, steps_per_epoch=100, epochs=100, validation_data=validation_generator_x, validation_steps=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 44s 418ms/step - loss: 0.6959 - acc: 0.5119 - val_loss: 0.6862 - val_acc: 0.5788\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 41s 408ms/step - loss: 0.6884 - acc: 0.5369 - val_loss: 0.6747 - val_acc: 0.5813\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 41s 406ms/step - loss: 0.6774 - acc: 0.5494 - val_loss: 0.6763 - val_acc: 0.5400\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 0.6657 - acc: 0.5788 - val_loss: 0.6558 - val_acc: 0.6075\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 0.6736 - acc: 0.5675 - val_loss: 0.6492 - val_acc: 0.6150\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 38s 380ms/step - loss: 0.6565 - acc: 0.5800 - val_loss: 0.6604 - val_acc: 0.5913\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 35s 353ms/step - loss: 0.6693 - acc: 0.5919 - val_loss: 0.6521 - val_acc: 0.6187\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 35s 345ms/step - loss: 0.6461 - acc: 0.5994 - val_loss: 0.6455 - val_acc: 0.6100\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 36s 355ms/step - loss: 0.6600 - acc: 0.5981 - val_loss: 0.6251 - val_acc: 0.6475\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 35s 347ms/step - loss: 0.6538 - acc: 0.6062 - val_loss: 0.6629 - val_acc: 0.5975\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 34s 336ms/step - loss: 0.6566 - acc: 0.6019 - val_loss: 0.6350 - val_acc: 0.6400\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 34s 339ms/step - loss: 0.6555 - acc: 0.6019 - val_loss: 0.6425 - val_acc: 0.6125\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 33s 327ms/step - loss: 0.6411 - acc: 0.6294 - val_loss: 0.6313 - val_acc: 0.6150\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.6560 - acc: 0.6181 - val_loss: 0.6943 - val_acc: 0.5200\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 33s 324ms/step - loss: 0.6374 - acc: 0.6162 - val_loss: 0.6301 - val_acc: 0.6600\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.6353 - acc: 0.6356 - val_loss: 0.6010 - val_acc: 0.6925\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.6308 - acc: 0.6388 - val_loss: 0.6135 - val_acc: 0.6463\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.6430 - acc: 0.6194 - val_loss: 0.6347 - val_acc: 0.6175\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 0.6272 - acc: 0.6506 - val_loss: 0.6004 - val_acc: 0.6950\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.6274 - acc: 0.6600 - val_loss: 0.6234 - val_acc: 0.6562\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 32s 316ms/step - loss: 0.6417 - acc: 0.6306 - val_loss: 0.5987 - val_acc: 0.6787\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 0.6159 - acc: 0.6612 - val_loss: 0.5884 - val_acc: 0.6825\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.6263 - acc: 0.6475 - val_loss: 0.5967 - val_acc: 0.6825\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 0.6111 - acc: 0.6612 - val_loss: 0.5799 - val_acc: 0.6975\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 0.6136 - acc: 0.6506 - val_loss: 0.5723 - val_acc: 0.7188\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 32s 316ms/step - loss: 0.6227 - acc: 0.6425 - val_loss: 0.6096 - val_acc: 0.6562\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.5897 - acc: 0.6800 - val_loss: 0.7547 - val_acc: 0.5575\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.6196 - acc: 0.6650 - val_loss: 0.6048 - val_acc: 0.6475\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.6164 - acc: 0.6544 - val_loss: 0.5954 - val_acc: 0.6662\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 32s 316ms/step - loss: 0.6076 - acc: 0.6619 - val_loss: 0.5751 - val_acc: 0.7038\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.6033 - acc: 0.6756 - val_loss: 0.5744 - val_acc: 0.6988\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 0.6146 - acc: 0.6587 - val_loss: 0.5693 - val_acc: 0.6963\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 0.5938 - acc: 0.6694 - val_loss: 0.5470 - val_acc: 0.7100\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.5952 - acc: 0.6850 - val_loss: 0.5456 - val_acc: 0.7163\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.6112 - acc: 0.6700 - val_loss: 0.6050 - val_acc: 0.6375\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.5976 - acc: 0.6694 - val_loss: 0.5948 - val_acc: 0.6837\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.6002 - acc: 0.6769 - val_loss: 0.5475 - val_acc: 0.7412\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.5977 - acc: 0.6775 - val_loss: 0.5360 - val_acc: 0.7250\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.5765 - acc: 0.6975 - val_loss: 0.5420 - val_acc: 0.7200\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 31s 304ms/step - loss: 0.5876 - acc: 0.6862 - val_loss: 0.5463 - val_acc: 0.7350\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.5961 - acc: 0.6819 - val_loss: 0.5436 - val_acc: 0.7513\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.5937 - acc: 0.6825 - val_loss: 0.5794 - val_acc: 0.6800\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.6017 - acc: 0.6587 - val_loss: 0.5800 - val_acc: 0.6875\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 31s 304ms/step - loss: 0.5790 - acc: 0.6981 - val_loss: 0.5754 - val_acc: 0.6913\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.5859 - acc: 0.6775 - val_loss: 0.5655 - val_acc: 0.7100\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 0.5920 - acc: 0.6819 - val_loss: 0.6621 - val_acc: 0.6125\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.5756 - acc: 0.6963 - val_loss: 0.5398 - val_acc: 0.7287\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 0.5832 - acc: 0.6819 - val_loss: 0.5753 - val_acc: 0.7113\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.5677 - acc: 0.7138 - val_loss: 0.5507 - val_acc: 0.7150\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 0.5971 - acc: 0.6875 - val_loss: 0.5570 - val_acc: 0.7163\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 0.5766 - acc: 0.6969 - val_loss: 0.5239 - val_acc: 0.7375\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 0.5749 - acc: 0.7063 - val_loss: 0.5368 - val_acc: 0.7300\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.5806 - acc: 0.6938 - val_loss: 0.5221 - val_acc: 0.7538\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.5822 - acc: 0.6850 - val_loss: 0.5099 - val_acc: 0.7437\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 0.5590 - acc: 0.7069 - val_loss: 0.5316 - val_acc: 0.7350\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.5660 - acc: 0.6956 - val_loss: 0.5601 - val_acc: 0.6950\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.6045 - acc: 0.6875 - val_loss: 0.5491 - val_acc: 0.7250\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.5675 - acc: 0.7081 - val_loss: 0.5229 - val_acc: 0.7412\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 0.5716 - acc: 0.6944 - val_loss: 0.5601 - val_acc: 0.7163\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.5722 - acc: 0.7113 - val_loss: 0.5463 - val_acc: 0.7212\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 31s 304ms/step - loss: 0.5659 - acc: 0.7119 - val_loss: 0.5161 - val_acc: 0.7487\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.5604 - acc: 0.7150 - val_loss: 0.5885 - val_acc: 0.6900\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.5642 - acc: 0.7081 - val_loss: 0.5226 - val_acc: 0.7487\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.5678 - acc: 0.7119 - val_loss: 0.5664 - val_acc: 0.6850\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 33s 329ms/step - loss: 0.5613 - acc: 0.7188 - val_loss: 0.5000 - val_acc: 0.7725\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.5556 - acc: 0.7119 - val_loss: 0.5936 - val_acc: 0.6662\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 0.5465 - acc: 0.7225 - val_loss: 0.5893 - val_acc: 0.6587\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.5613 - acc: 0.7000 - val_loss: 0.5023 - val_acc: 0.7400\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 0.5575 - acc: 0.7244 - val_loss: 0.5032 - val_acc: 0.7613\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.5535 - acc: 0.7131 - val_loss: 0.6072 - val_acc: 0.6637\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.5558 - acc: 0.7131 - val_loss: 0.5137 - val_acc: 0.7513\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 6427s 65s/step - loss: 0.5456 - acc: 0.7312 - val_loss: 0.6414 - val_acc: 0.6625\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 31s 304ms/step - loss: 0.5458 - acc: 0.7219 - val_loss: 0.6175 - val_acc: 0.6787\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 0.5623 - acc: 0.7113 - val_loss: 0.5262 - val_acc: 0.7613\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 33s 324ms/step - loss: 0.5678 - acc: 0.7094 - val_loss: 0.4963 - val_acc: 0.7525\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 0.5710 - acc: 0.7081 - val_loss: 0.4989 - val_acc: 0.7425\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 33s 325ms/step - loss: 0.5569 - acc: 0.7119 - val_loss: 0.5816 - val_acc: 0.6800\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 0.5569 - acc: 0.7144 - val_loss: 0.5094 - val_acc: 0.7262\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.5517 - acc: 0.7206 - val_loss: 0.5426 - val_acc: 0.7387\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.5602 - acc: 0.7000 - val_loss: 0.4915 - val_acc: 0.7588\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.5629 - acc: 0.6894 - val_loss: 0.5263 - val_acc: 0.7437\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 0.5310 - acc: 0.7281 - val_loss: 0.6983 - val_acc: 0.6725\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.5406 - acc: 0.7275 - val_loss: 0.5330 - val_acc: 0.7163\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.5737 - acc: 0.7000 - val_loss: 0.5617 - val_acc: 0.7212\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 0.5636 - acc: 0.7219 - val_loss: 0.5177 - val_acc: 0.7412\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 0.5559 - acc: 0.7237 - val_loss: 0.6515 - val_acc: 0.6913\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.5544 - acc: 0.6963 - val_loss: 0.6168 - val_acc: 0.6800\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 0.5519 - acc: 0.7194 - val_loss: 0.5379 - val_acc: 0.7350\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 0.5379 - acc: 0.7194 - val_loss: 0.5199 - val_acc: 0.7425\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.5612 - acc: 0.7156 - val_loss: 0.5346 - val_acc: 0.7237\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 32s 315ms/step - loss: 0.5534 - acc: 0.7088 - val_loss: 0.5577 - val_acc: 0.7337\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.5494 - acc: 0.7200 - val_loss: 0.4481 - val_acc: 0.7962\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 33s 328ms/step - loss: 0.5415 - acc: 0.7331 - val_loss: 0.5918 - val_acc: 0.7075\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.5414 - acc: 0.7306 - val_loss: 0.5156 - val_acc: 0.7387\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.5412 - acc: 0.7306 - val_loss: 0.4819 - val_acc: 0.7738\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 0.5547 - acc: 0.7294 - val_loss: 0.4832 - val_acc: 0.7775\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 33s 329ms/step - loss: 0.5488 - acc: 0.7206 - val_loss: 0.5128 - val_acc: 0.7400\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 35s 344ms/step - loss: 0.5555 - acc: 0.7225 - val_loss: 0.6729 - val_acc: 0.6963\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.5374 - acc: 0.7306 - val_loss: 0.5367 - val_acc: 0.7400\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 35s 349ms/step - loss: 0.5462 - acc: 0.7287 - val_loss: 0.6096 - val_acc: 0.6775\n",
      "info: Done!\n"
     ]
    }
   ],
   "source": [
    "#training new model\n",
    "history_x =model_x.fit_generator(train_generator_x, steps_per_epoch=100, epochs=100, validation_data=validation_generator_x, validation_steps=50)\n",
    "print(\"info: Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e3624-db17-4b41-ad44-9ccf4cabf1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization new model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use(\"seaborn-darkgrid\")\n",
    "plt.figure()\n",
    "epochs=100\n",
    "\n",
    "plt.plot(np.arange(0,epochs), history_x.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0,epochs), history_x.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0,epochs), history_x.history[\"acc\"], label=\"acc\")\n",
    "plt.plot(np.arange(0,epochs), history_x.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training | Loss & Accuracy)\n",
    "plt.xlabel(\"100 - epoch\")\n",
    "plt.ylabel(\"Loss & Accuracy\")\n",
    "plt.legend(loc =\"lower left\")\n",
    "\n",
    "model_x.save(\"model/cat_dog_last.h5\")\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd2a688-4e10-474d-9f05-9e27316319ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "model_path=\"models/cat_dog_last.h5\"\n",
    "image_path=\"datasets/catdog/test/dog/1500.jpg\"\n",
    "\n",
    "prediction_model = load_model(model_path)\n",
    "test_img=load_img(image_path, target_size=(150,150))\n",
    "print(test_img)\n",
    "test_img #bu satıra gerek yok sadece resmin gelip gelmeyeceğini öğrenmek için var \n",
    "test_img = img_to_array(test_img)\n",
    "test_img.shape #4D dönüştürüldü\n",
    "train_generator_x.class_indices\n",
    "result =prediction_model.predict(test_img)\n",
    "result #bu satıra gerek yok çıktıyı kontrol ediyoruz sadece \n",
    "\n",
    "if result [0][0] > 0.5:\n",
    "    label=\"Dog\"\n",
    "    print(\"Prediction: This is a\". label)\n",
    "\n",
    "else:\n",
    "    label=\"Cat\"\n",
    "    print(\"Prediction: This is a\", label)\n",
    "\n",
    "import cv2\n",
    "test_img=cv2.imread(image_path)\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "color(255,255,0)\n",
    "cv2.putText(test_img, label,(20,40), font, 1.0, color, 3)\n",
    "cv2.imshow(\"Prediction\", test_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef871f-d20b-4236-9bfe-f2d492eb11c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
